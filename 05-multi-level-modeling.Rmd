# Multi Level Models

## Introduction

```{r}
library(lme4)
library(foreign)
library(broom)
library(tidyverse)
```



*Fixed-effect* parameters only use data for a specific group.  In contrast, *random-effect* parameters assume data share a common distribution.  FOr situations with small amounts of data or ourliers, random effect models can produce different estimates.




```{r}

evolution<-read.dta("http://j.mp/BPchap7")
evolution$female[evolution$female==9]<-NA
evolution<-subset(evolution,!is.na(female))
```

### full model
```{r}
hours_ml<-lmer(hrs_allev ~ phase1 + senior_c + ph_senior + notest_p + ph_notest_p + female + biocred3 + 
                 degr3 + evol_course + certified + idsci_trans + confident + (1|st_fip), data = evolution)
```




### building the model

Here we are building a random effects with no fixed effects:
```{r}
initial <- lmer(hrs_allev ~ (1 | st_fip), data = evolution)

summary(initial)
```

```{r}
plot(initial)
```


Now let's build one with a fixed-effect slope parameter:

```{r}
fixed <- lmer(hrs_allev ~ phase1 + (1 | st_fip), data = evolution)

summary(fixed)
```


Now to add a random slope:
```{r}
random_slopes <- lmer(hrs_allev ~ phase1 + (notest_p | st_fip), data = evolution)

broom::tidy(random_slopes)
```


If we wanted to assume uncorrelated random-effect slopes (it is actually easier to calculate) all we have to do is turn `|` into `||` (though you likely want a reason to do this, I am just doing here for instruction)

```{r}
uncor <- lmer(hrs_allev ~ phase1 + (notest_p || st_fip), data = evolution)

summary(uncor)
```


You can also have a variable as a fixed effect while correcting for random slopes:


```{r}
# fixed_random <- lmer(hrs_allev ~ phase1 + (phase1 || st_fip), data = evolution)
# 
# summary(fixed_random)
```

### Understanding and reporting the outputs

Point estimates

```{r}
# fixef(fixed_random)
```


```{r}
# ranef(fixed_random)
```

We can also get confidence interals for the fixed effects using confint()

```{r}
# confint(fixed_random)
```



Using the broom.mixed package, you can use the `tidy()` function to extract model results, though this isn't as tidy as most models are:

```{r}
library(broom)

# tidy(fixed_random, conf.int = TRUE)
```


### Communicating results

This is not very easy to extract lmer results (see [link](https://github.com/tidymodels/broom/issues/96)).  

```{r}
# # Extract out the parameter estimates and confidence intervals and manipulate the data
# dataPlot <- data.frame(cbind( fixef(fixed_random), confint(fixed_random)[ 4:5, ])) # getting the rows for confint
# rownames(dataPlot)[1] <- "Intercept"
# colnames(dataPlot) <- c("est", "L95", "U95")
# dataPlot$parameter <- rownames(dataPlot)
# 
# # Print the new dataframe
# print(dataPlot)
# 
# # Plot the results using ggplot2
# ggplot(dataPlot, aes(x = parameter, y = est, ymin = L95, ymax = U95)) +
#   geom_hline( yintercept = 0, color = 'red' ) +
#   geom_linerange() + 
#   geom_point() + 
#   coord_flip() + 
#   theme_minimal()
```


It is important that in many instances, rescaling might have to occur to make the model numerically viable (for instance, changing the year in our study to be 0 instead of the actual year).


### Model comparison with Anova

What happens if we include more variables or model it differently?  Well we can use anove to determine which model is better:
```{r}
# anova(random_slopes, fixed_random)
```
In this instance the fixed_random does a better job, but is not significantly better.


## GLMs

### Binomial Data

code: glmer(y ~ x + (1  | group), family = 'error term')


Here we are using the Bang dataset which is a survey of contraception use for women in Bangladesh.  The variables we are using for the model is whether they used the contraception (`user`), then the number of living children they had (`living.children`), the age centered around the mean (`age_mean`), and whether they lived in an urban or rural area (`urban`).  The random intercept in this case is the `district` where they reside.
```{r}
library(epiDisplay)

data(Bang)

cont_model <- glmer(user ~ living.children + age_mean + urban + (1 | district),
                    family = "binomial",
                    data = Bang)
```


Now let's look at the results
```{r}
summary(cont_model)

```

Everything is significant, and pretty much what we would expect.  The more kids, the more likely you are to use it,  The older you are, the less likely you are.  And women in urban areas use them more.  The coefficients however, are difficult to read becasue they are in log-dds.  We can change this to odds ratios by taking the exponent.  Here is a short explanation of odds-ratios:

- If an odds-ratio is 1.0, then both events have an equal chance of occurring. For example, if the odds-ratio for a urban was 1.0, then living in an urban/rural area would have no influence on contraception use.
- If an odds-ratio is less than 1, then living in an urban area would decrease the chance of using contraception. For example, an odds-ratio of 0.5 would mean a those living in urban areas have odds of 1:2 or 1 woman using contraception for every 2 women in rural areas.
- If an odds-ratio is greater than 1, then living in an urban area would increase the chance of contraception use. For example, an odds-ratio of 3.0 would mean living in an urban area has odds of 3:1 or 3 women using contraception in an urban area compared to those in rural areas.


```{r}
# calculating odds ratios and the confidence intervals for them
exp(fixef(cont_model))
exp(confint(cont_model))
```



### Count models

pretty simple change in formula: `glmer(y ~ x + (1 | group), family = 'poisson')`

Here we are using data about chlamydia given by the state of illinois. We basically want to see if things are getting better over time, and whether age groups have this problem at different rates.

```{r}
chlamydia <- read_csv("https://assets.datacamp.com/production/repositories/1803/datasets/612bd6490500636efa74132bfbc37817f250cb5a/ILdata.csv")
```


```{r}
count_chlamydia <- glmer(count ~ age + year + (year | county), family = "poisson",
                         data = chlamydia)
summary(count_chlamydia)

```

So there is a difference by age group for 2 categories.  Now let's show them in a good format:

```{r}
fixef(count_chlamydia)
ranef(count_chlamydia)
```

We can plot this in a similar fashion using ggplot, though it won't be exactly the same as the `glmer()` outputs: (UGLY)
```{r}
# fits 4 graphs with I believe 47 lines for the actual data and 47 predicted
ggplot(chlamydia, aes(x = year, y = count, group = county)) +
  geom_line() +
  facet_grid(age ~ .) +
  stat_smooth(method = "glm", method.args = list(
    family = "poisson"), se = FALSE, alpha = 0.5) +
  theme_minimal()
```

I think this still works, but gives a few number of counties:
```{r}
chlamydia %>%
  filter(county == sample(county, 10)) %>%
  ggplot(aes(x = year, y = count, group = county)) +
  geom_line() +
  facet_grid(age ~ .) +
  stat_smooth(method = "glm", method.args = list(
    family = "poisson"), se = FALSE, alpha = 0.5) +
  theme_minimal()
```


## Repeated Measures

They are a special case of mixed-effects models.  Following individuals through time.  We may do a paired, t-test.  You can also do a repeated measures ANOVA from more than just 2 tests (it could be test scores for every year of score).

There is no default measure for running a repeated measure ANOVA by doing:

`library(lmertest)`
`anova(lmer(y ~ time + (1|individual)))`


This can also do this for lmer nad glmer.  Need to add a time variable and a group variable.


### Paired T-test


We are going to show this with randomly simulated data of 10 observations.
```{r}
# Set the seed to be 345659
set.seed(345659)


# simulate before with mean of 0 and sd of 0.5
before <- rnorm(10, mean = 0, sd = 0.5)
# simulate after with mean effect of 4.5 and standard devation of 5
after  <- before + rnorm(10, mean = 4.5, sd = 5)

# Run a standard, non-paired t-test
t.test(x = before, y =after, paired = FALSE)

# Run a standard, paired t-test
t.test(x = before, y =after, paired = TRUE)
```

In this case, both the paired and the unpaired versions were significant, but the paired one showed a larger difference (more powerful).  



### Repeated Measures ANOVA

here we are going to use this process but for repeated (more than 2) measures using ANOVA.  First, though, we have to create a data frame using the variables from the last section.
```{r}
# Create the data.frame, using the variables from the previous exercise. 
# y is the joined vectors before and after.
# trial is the repeated names before and after, each one repeated n_ind
# ind is the letter of the individual, repeated 2 times (because there were two observations)
dat <- data.frame(y = c(before, after), 
                  trial = rep(c("before", "after"), each = 10),
                  ind = rep(letters[1:10], times = 2))
```


```{r}
library(lmerTest)

# Run a standard, paired t-test
t.test(before, after, paired = TRUE)

# Run a lmer and save it as lmer_out
lmer_out <- lmer(y ~ trial + (1| ind), data = dat)

# Look at the summary() of lmer_out
summary(lmer_out)
```

In this case, the intercept is the same for the lmer and the t.test!  So the lmer is basically an extension fo the paired t.test.


### Example: NY Hate Crime Data


```{r}
hate <- read_csv("https://assets.datacamp.com/production/repositories/1803/datasets/45e88fe1bc8d1d76d140e69cb873da9eddb7008e/hateNY.csv")

hate
```

Give the different population sizes of New York counties, you can reasonably assume the need for random-effect intercepts a priori. However, do you need random-effect slopes? Plot the data to see if trends appear to vary by county. Additionally, plotting the data will help you see what is going on.


```{r}
ggplot(hate, aes(x = Year, y = TotalIncidents, group = County)) +
  geom_line() +
  geom_smooth(method = "glm", method.args = c("poisson"), se = FALSE)
```

From the graph above, it looks like we need both random intercepts and random slopes.

Now let's build a simple `glm` model and then we cna move onto `glmer`.  

```{r}
ny_hate_mod1 <- glm(TotalIncidents ~ Year + County, data = hate, family = "poisson")

summary(ny_hate_mod1)
```

Now that our model ran without any problems, let's build a `glmer()`:

```{r}
ny_hate_mod2 <- glmer(TotalIncidents ~ Year + (Year | County), data = hate, family = "poisson")

summary(ny_hate_mod2)
```

We got a wnrning about having a problem and needing to rescale, we can do this by using the Year2 variable instead of the Year variable (rescaling can help a lot with this)

```{r}
ny_hate_mod3 <- glmer(TotalIncidents ~ Year2 + (Year2 | County), data = hate, family = "poisson")

summary(ny_hate_mod3)
```


Now let's visualize the results:


During this exercise, we'll extract out the county-level estimates and plot them with ggplot2. The county-level random-effect slopes need to be added to the fixed-effect slopes to get the slope estimates for each county.

In addition to this addition, the code includes ordering the counties by rate of crime (the slope estimates) to help visualize the data clearly.
```{r}
# Extract out the fixed-effect slope for Year2
Year2_slope <- fixef(ny_hate_mod3)['Year2']

# Extract out the random-effect slopes for county
county_slope <- ranef(ny_hate_mod3)$County

# Create a new column for the slope
county_slope$slope <- county_slope$Year2 + Year2_slope

# Use the row names to create a county name column
county_slope$county <- rownames(county_slope)

# Create an ordered county-level factor based upon slope values
county_slope$county_plot <- factor(county_slope$county, 
                                   levels = county_slope$county[order(county_slope$slope)])

# Now plot the results using ggplot2
ggplot(data = county_slope, aes(x = county_plot, y = slope)) + 
	geom_point() +
    coord_flip() + 
	theme_bw() + 
	ylab("Change in hate crimes per year")  +
	xlab("County")
```

Note how the change in hate crimes varies greatly across countries!


